import math
import qbittorrentapi
import csv
import sys
import datetime
from collections import defaultdict
import yaml
import os

# è¯»å–ä¸»é…ç½®æ–‡ä»¶
with open("config.yml", "r", encoding="utf-8") as f:  # æ·»åŠ  encoding="utf-8"
    main_config = yaml.safe_load(f)
env_name = main_config["use_env"]

# è¯»å–ç¯å¢ƒç‰¹å®šçš„é…ç½®æ–‡ä»¶
config_path = os.path.join("config", f"{env_name}.yaml")
with open(config_path, "r", encoding="utf-8") as f:  # æ·»åŠ  encoding="utf-8"
    config = yaml.safe_load(f)
    
# ä»é…ç½®æ–‡ä»¶ä¸­æå–é…ç½®
qb_host = config["qbittorrent"]["host"]
qb_port = config["qbittorrent"]["port"]
qb_username = config["qbittorrent"]["username"]
qb_password = config["qbittorrent"]["password"]
delete_files_on_remove = config["delete_files_on_remove"]
required_trackers = config["required_trackers"]
required_summer = config["required_summer"]
upload_speed_limits_by_tracker = config["upload_speed_limits_by_tracker"]
export_deduplicate = config.get("export_options", {}).get("deduplicate", True)

# ç™»å½•å®¢æˆ·ç«¯

client = qbittorrentapi.Client(
    host=qb_host, port=qb_port, username=qb_username, password=qb_password
)
try:
    client.auth_log_in()
    print("ç™»å½•æˆåŠŸï¼")
except qbittorrentapi.LoginFailed as e:
    print(f"ç™»å½•å¤±è´¥: {e}")
    exit(1)
    
def convert_size(size_bytes):
    """
    å°†å­—èŠ‚å¤§å°è½¬æ¢ä¸ºåˆé€‚çš„å•ä½
    :param size_bytes: å­—èŠ‚å¤§å°
    :return: è½¬æ¢åçš„å­—ç¬¦ä¸²ï¼Œå¦‚ "1.23 GB"
    """
    if size_bytes == 0:
        return "0 B"
    units = ("B", "KB", "MB", "GB", "TB", "PB")
    i = min(int(math.log(size_bytes, 1024)), len(units) - 1)
    size = round(size_bytes / (1024 ** i), 2)
    return f"{size} {units[i]}"


def check_missing_trackers():
    torrents = client.torrents.info()
    grouped = defaultdict(list)
    for torrent in torrents:
        key = (torrent.name, torrent.total_size)
        grouped[key].append(torrent)
    results = []
    for (name, size), torrent_group in grouped.items():
        all_trackers = set()
        tracker_comment_pairs = set()
        hashes = []
        for t in torrent_group:
            hashes.append(t.hash)
            trackers = client.torrents.trackers(t.hash)
            valid_trackers = [
                tracker.url
                for tracker in trackers
                if not any(x in tracker.url for x in ["[DHT]", "[PeX]", "[LSD]"])
            ]
            for tracker_url in valid_trackers:
                all_trackers.add(tracker_url)
            try:
                properties = client.torrents_properties(t.hash)
                comment = properties.comment or ""
                if comment:  # Only create tracker-comment pairs for non-empty comments
                    for tracker_url in valid_trackers:
                        pair = f"ç«™ç‚¹trackerï¼š{tracker_url}-->>>æ³¨é‡Šï¼š{comment}"
                        tracker_comment_pairs.add(pair)
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•è·å–ç§å­ {name} çš„è¯„è®º: {e}")

        # If ANY of the torrent's trackers match ANY of the required trackers, skip it.
        if any(any(req in url for req in required_trackers) for url in all_trackers):
            continue

        # Otherwise, the torrent is missing all required trackers, so add it to the results.
        results.append(
            {
                "name": name,
                "size": size,
                "trackers": list(all_trackers),
                "hashes": hashes,
                "comment": "\n".join(sorted(tracker_comment_pairs)),  # Merge tracker-comment pairs
            }
        )
    return results

def export_missing_trackers(filename="missing_trackers.csv"):
    result = check_missing_trackers()
    total_size = sum(item["size"] for item in result)
    
    with open(filename, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["ç§å­åç§°", "å¤§å°ï¼ˆå­—èŠ‚ï¼‰", "æ‰€æœ‰ Tracker", "ç§å­æ³¨é‡Š"])
        for item in result:
            writer.writerow([item["name"], item["size"], ", ".join(item["trackers"]), item["comment"]])
        writer.writerow([])
        writer.writerow(["æ€»è®¡", f"{total_size} å­—èŠ‚", f"({convert_size(total_size)})", ""])
    
    print(f"âœ… å¯¼å‡ºå®Œæˆï¼Œå…± {len(result)} é¡¹ï¼Œæ€»å¤§å° {convert_size(total_size)} â†’ {filename}")


def delete_missing_trackers():
    result = check_missing_trackers()
    total = 0
    for item in result:
        for h in item["hashes"]:
            try:
                client.torrents_delete(
                    delete_files=delete_files_on_remove, torrent_hashes=h
                )
                print(f"å·²åˆ é™¤ï¼š{item['name']} - {h}")
                total += 1
            except Exception as e:
                print(f"åˆ é™¤å¤±è´¥ï¼š{item['name']} - {h}ï¼ŒåŸå› ï¼š{e}")
    print(f"âœ… å…±åˆ é™¤ {total} ä¸ªç§å­")


def delete_specific_torrent(name, size):
    torrents = client.torrents.info()
    deleted = 0
    for torrent in torrents:
        if torrent.name == name and torrent.total_size == size:
            try:
                client.torrents_delete(
                    delete_files=delete_files_on_remove, torrent_hashes=torrent.hash
                )
                print(f"âœ… å·²åˆ é™¤ï¼š{torrent.name} - {torrent.hash}")
                deleted += 1
            except Exception as e:
                print(f"âŒ åˆ é™¤å¤±è´¥ï¼š{torrent.name} - {torrent.hash}ï¼ŒåŸå› ï¼š{e}")
    if deleted == 0:
        print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„ç§å­")
    else:
        print(f"âœ… å…±åˆ é™¤ {deleted} ä¸ªç§å­")


def limit_upload_speed_by_tracker():
    torrents = client.torrents_info()
    modified = 0
    skipped = 0
    failed = 0
    for torrent in torrents:
        try:
            trackers = client.torrents_trackers(torrent.hash)
            matched_speed = None
            matched_tracker = None
            current_limit = torrent.up_limit
            needs_update = False
            for tracker in trackers:
                url = tracker.url
                if any(proto in url for proto in ["[DHT]", "[PeX]", "[LSD]"]):
                    continue
                for domain, speed_kb in upload_speed_limits_by_tracker.items():
                    if domain in url:
                        desired_limit = speed_kb * 1024
                        if current_limit != desired_limit:
                            matched_speed = speed_kb
                            matched_tracker = url
                            needs_update = True
                        break
                if matched_speed is not None:
                    break
            if needs_update and matched_speed is not None:
                upload_limit = matched_speed * 1024
                try:
                    was_paused = torrent.state == "pausedUP"
                    if not was_paused:
                        client.torrents_pause(torrent.hash)
                    client.torrents_set_upload_limit(
                        limit=upload_limit, torrent_hashes=torrent.hash
                    )
                    if not was_paused:
                        client.torrents_resume(torrent.hash)
                    print(
                        f"âœ… é™é€Ÿï¼š{torrent.name} â†’ {matched_speed} KB/sï¼ˆtracker: {matched_tracker}ï¼‰"
                    )
                    modified += 1
                except Exception as e:
                    print(
                        f"âŒ é™é€Ÿå¤±è´¥ï¼š{torrent.name}ï¼ˆ{matched_tracker} â†’ {matched_speed} KB/sï¼‰â†’ {str(e)}"
                    )
                    failed += 1
            else:
                reason = "å·²ç¬¦åˆè¦æ±‚" if matched_speed else "æœªåŒ¹é…åˆ°é™é€Ÿ tracker"
                # print(f"âš ï¸ è·³è¿‡ï¼š{torrent.name}ï¼ˆ{reason}ï¼‰")

                skipped += 1
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥ï¼š{torrent.name} â†’ {str(e)}")
            failed += 1
    print(
        f"\nâœ… å®Œæˆï¼šå…±é™åˆ¶ {modified} ä¸ªç§å­ä¸Šä¼ é€Ÿåº¦ï¼Œè·³è¿‡ {skipped} ä¸ªç§å­ï¼Œå¤±è´¥ {failed} ä¸ª"
    )


def export_tracker_summary(filename="tracker_summary.csv"):
    torrents = client.torrents_info()
    results = []
    total_size = 0
    for torrent in torrents:
        trackers = client.torrents_trackers(torrent.hash)
        valid_trackers = [
            t.url
            for t in trackers
            if not any(proto in t.url for proto in ["[DHT]", "[PeX]", "[LSD]"])
        ]
        matched = [
            trk for trk in valid_trackers if any(req in trk for req in required_summer)
        ]
        if matched:
            created_on = datetime.datetime.fromtimestamp(torrent.added_on).strftime("%Y-%m-%d %H:%M:%S")
            results.append({
                "name": torrent.name,
                "size": torrent.total_size,
                "created_on": created_on,
                "matched_trackers": ", ".join(matched),
            })
            total_size += torrent.total_size
    
    with open(filename, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["ç§å­åç§°", "å¤§å°ï¼ˆå­—èŠ‚ï¼‰", "åˆ›å»ºæ—¶é—´", "åŒ¹é…çš„ Tracker"])
        for item in results:
            writer.writerow([
                item["name"],
                item["size"],
                item["created_on"],
                item["matched_trackers"],
            ])
        # æ–°å¢ç»Ÿè®¡è¡Œ
        writer.writerow([])
        writer.writerow(["æ€»è®¡", f"{total_size} å­—èŠ‚", f"({convert_size(total_size)})", ""])
    
    print(f"âœ… å¯¼å‡ºå®Œæˆï¼š{len(results)} ä¸ªç§å­ï¼Œæ€»å¤§å° {convert_size(total_size)} â†’ {filename}")
    print(f"ğŸ“¦ æ€»å¤§å°ï¼š{total_size} å­—èŠ‚ï¼ˆ{convert_size(total_size)}ï¼‰")


def export_torrents_by_filter(
    keyword=None, 
    min_size=None, 
    max_size=None, 
    filename="filtered_torrents.csv"
):
    print(f"DEBUG: export_deduplicate = {export_deduplicate}")
    torrents = client.torrents_info()
    results = []
    total_size = 0  # Initialize total_size here
    
    if export_deduplicate:
        grouped = defaultdict(list)
        for torrent in torrents:
            if keyword and keyword.lower() not in torrent.name.lower():
                continue
            if min_size and torrent.total_size < min_size:
                continue
            if max_size and torrent.total_size > max_size:
                continue
            key = (torrent.name, torrent.total_size)
            grouped[key].append(torrent)
        
        for (name, size), torrent_group in grouped.items():
            # åˆå¹¶æ‰€æœ‰trackerï¼ˆå»é‡ï¼‰
            all_trackers = set()
            created_on = None
            for t in torrent_group:
                trackers = client.torrents_trackers(t.hash)
                for tracker in trackers:
                    url = tracker.url
                    if not any(x in url for x in ["[DHT]", "[PeX]", "[LSD]"]):
                        all_trackers.add(url)
                # å–æœ€æ—©çš„åˆ›å»ºæ—¶é—´
                added_on = datetime.datetime.fromtimestamp(t.added_on)
                if created_on is None or added_on < created_on:
                    created_on = added_on
            
            results.append({
                "name": name,
                "size": size,
                "created_on": created_on.strftime("%Y-%m-%d %H:%M:%S"),
                "trackers": ", ".join(all_trackers),
            })
            total_size += size  # Add size after deduplication
    else:
        for torrent in torrents:
            if keyword and keyword.lower() not in torrent.name.lower():
                continue
            if min_size and torrent.total_size < min_size:
                continue
            if max_size and torrent.total_size > max_size:
                continue
                
            created_on = datetime.datetime.fromtimestamp(torrent.added_on).strftime(
                "%Y-%m-%d %H:%M:%S"
            )
            trackers = client.torrents_trackers(torrent.hash)
            all_trackers = [
                t.url
                for t in trackers
                if not any(proto in t.url for proto in ["[DHT]", "[PeX]", "[LSD]"])
            ]
            results.append({
                "name": torrent.name,
                "size": torrent.total_size,
                "created_on": created_on,
                "trackers": ", ".join(all_trackers),
            })
            total_size += torrent.total_size  # Add size for non-deduplicated case

    # å†™å…¥CSVæ–‡ä»¶
    with open(filename, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["ç§å­åç§°", "å¤§å°ï¼ˆå­—èŠ‚ï¼‰", "åˆ›å»ºæ—¶é—´", "æ‰€æœ‰ Tracker"])
        for item in results:
            writer.writerow(
                [item["name"], item["size"], item["created_on"], item["trackers"]]
            )
        # æ–°å¢ä¸€è¡Œç»Ÿè®¡ä¿¡æ¯
        writer.writerow([])  # ç©ºè¡Œåˆ†éš”
        writer.writerow(["æ€»è®¡", f"{total_size} å­—èŠ‚", f"({convert_size(total_size)})", ""])
    
    print(f"âœ… å¯¼å‡ºå®Œæˆï¼Œå…± {len(results)} é¡¹ï¼Œæ€»å¤§å° {convert_size(total_size)} â†’ {filename}")
    

# ========== ä¸»å‡½æ•°ï¼Œæ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ‰§è¡Œ ==========

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(
            "â—ç”¨æ³•:\n  python qbt.py export\n  python qbt.py del\n  python qbt.py del <ç§å­åç§°> <å¤§å°>\n  python qbt.py limit\n  python qbt.py total\n  python qbt.py search <å…³é”®è¯> [æœ€å°å¤§å° å•ä½å­—èŠ‚] [æœ€å¤§å¤§å° å•ä½å­—èŠ‚]"
        )
        sys.exit(1)
    cmd = sys.argv[1].lower()

    if cmd == "export":
        export_missing_trackers()
    elif cmd == "del":
        if len(sys.argv) == 2:
            delete_missing_trackers()
        elif len(sys.argv) == 4:
            name = sys.argv[2]
            try:
                size = int(sys.argv[3])
                delete_specific_torrent(name, size)
            except ValueError:
                print("âŒ ç¬¬ä¸‰ä¸ªå‚æ•°å¿…é¡»æ˜¯æ•´æ•°å¤§å°ï¼ˆå­—èŠ‚ï¼‰")
        else:
            print("â—ç”¨æ³•: python qbt.py del <ç§å­åç§°> <å¤§å°ï¼ˆå­—èŠ‚ï¼‰>")
    elif cmd == "limit":
        limit_upload_speed_by_tracker()
    elif cmd == "total":
        export_tracker_summary()
    elif cmd == "search":
        keyword = sys.argv[2] if len(sys.argv) > 2 else None
        min_size = int(sys.argv[3]) if len(sys.argv) > 3 else None
        max_size = int(sys.argv[4]) if len(sys.argv) > 4 else None
        export_torrents_by_filter(keyword, min_size, max_size)
    else:
        print(f"â—æœªçŸ¥æŒ‡ä»¤: {cmd}ï¼Œè¯·ç”¨ export / del / limit / total / search")
